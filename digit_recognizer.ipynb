{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import scipy.stats as st\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neural_Network():\n",
    "    def __init__(self, data, output, hls=20) -> None:\n",
    "        self.data = data\n",
    "        self.y = output\n",
    "        self.output_size = np.shape(output)[1]\n",
    "        self.hiddenL_size = hls\n",
    "        self.m = np.shape(data)[0]\n",
    "        self.n = np.shape(data)[1]\n",
    "\n",
    "        # Adding bias terms to weights\n",
    "        self.W1 = np.random.uniform(-0.5, 0.5, (self.hiddenL_size, self.n))\n",
    "        self.b1 = np.zeros((self.hiddenL_size, 1))  # Bias for the first layer\n",
    "        self.W2 = np.random.uniform(-0.5, 0.5, (self.output_size, self.hiddenL_size))\n",
    "        self.b2 = np.zeros((self.output_size, 1))  # Bias for the second layer\n",
    "\n",
    "        self.regularization = 5\n",
    "        self.loss = []\n",
    "\n",
    "    def run(self, epochs):\n",
    "        nr_correct = 0\n",
    "        for i in range(epochs):\n",
    "            print(f'epoch : {i}')\n",
    "            for img, l in zip(self.data[:], self.y[:]):\n",
    "                img.shape += (1,)\n",
    "                l.shape += (1,)\n",
    "                o = self.forward(img, l)\n",
    "\n",
    "                error = (1 / len(o)) * np.sum((o - l) ** 2, axis=0)\n",
    "                nr_correct += int(np.argmax(o) == np.argmax(l))\n",
    "\n",
    "                self.backward(o, img, l)\n",
    "            print(f\"Acc: {round((nr_correct / self.data.shape[0]) * 100, 3)}%\")\n",
    "            print(\" img shape \", np.shape(img))\n",
    "            print(f\" mean loss {np.mean(self.loss)}  error : {error}\")\n",
    "            self.loss = []\n",
    "            nr_correct = 0\n",
    "\n",
    "    def forward(self, img, y):\n",
    "        self.z1 = np.dot(self.W1, img) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.W2, self.a1) + self.b2\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        y_hat = self.a2\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def backward(self, o, img, y):\n",
    "        alpha = 0.01\n",
    "        delta_o = (o - y) * self.sigmoidPrime(o)\n",
    "        self.loss.append(np.mean(delta_o))\n",
    "\n",
    "        delta_a1 = np.dot(self.W2.T, delta_o) * self.sigmoidPrime(self.a1)\n",
    "\n",
    "        self.W2 += -alpha * (np.dot(delta_o, self.a1.T) + (self.regularization / self.m) * self.W2)\n",
    "        self.b2 += -alpha * np.sum(delta_o, axis=1, keepdims=True)\n",
    "\n",
    "        self.W1 += -alpha * (np.dot(delta_a1, img.T) + (self.regularization / self.m) * self.W1)\n",
    "        self.b1 += -alpha * np.sum(delta_a1, axis=1, keepdims=True)\n",
    "\n",
    "    def test(self, X):\n",
    "        z1 = np.dot(X, self.W1) + self.b1\n",
    "        a1 = self.sigmoid(z1)\n",
    "        z2 = np.dot(a1, self.W2) + self.b2\n",
    "        a2 = self.sigmoid(z2)\n",
    "        y_hat = a2\n",
    "\n",
    "        return y_hat\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoidPrime(self, a):\n",
    "        return a * (1 - a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000\n",
      "epoch : 0\n",
      "Acc: 62.354%\n",
      " img shape  (784, 1)\n",
      " mean loss 0.0009422534996811346  error : [0.01752923]\n"
     ]
    }
   ],
   "source": [
    "from data import get_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images , labels = get_mnist()\n",
    "split_per = int(len(images)*0.8)\n",
    "train_images= images[:split_per]\n",
    "train_labels= labels[:split_per]\n",
    "\n",
    "test_images= images[split_per:]\n",
    "test_labels= labels[split_per:]\n",
    "\n",
    "hls =20\n",
    "NN = Neural_Network(train_images,train_labels,hls)\n",
    "\n",
    "NN.run(1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m             index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter a number (0 - 9999): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m             img \u001b[38;5;241m=\u001b[39m test_images[index]\n\u001b[0;32m      4\u001b[0m             plt\u001b[38;5;241m.\u001b[39mimshow(img\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGreys\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "            index = int(input(\"Enter a number (0 - 9999): \"))\n",
    "            img = test_images[index]\n",
    "            plt.imshow(img.reshape(28, 28), cmap=\"Greys\")\n",
    "\n",
    "            img.shape += (1,)\n",
    "            # Forward propagation input -> hidden\n",
    "            z =  NN.W1 @ img.reshape(784, 1)\n",
    "            a = 1 / (1 + np.exp(-z))\n",
    "            # Forward propagation hidden -> output\n",
    "            a2 = + NN.W2@ a\n",
    "            o = 1 / (1 + np.exp(-a2))\n",
    "\n",
    "            plt.title(f\"Number guessed : {o.argmax()} \")\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb_hiddenLayers': 1, 'hiddenLayerSize': 20, 'weights1': array([[ 0.08220378, -0.03870507,  0.33231006, ..., -0.05348161,\n",
      "         0.07960643,  0.25302602],\n",
      "       [ 0.02257691, -0.29334793,  0.40775677, ...,  0.4486583 ,\n",
      "        -0.31742712,  0.47591137],\n",
      "       [-0.02083948,  0.28078986, -0.36415015, ...,  0.1063555 ,\n",
      "        -0.40213802,  0.35434814],\n",
      "       ...,\n",
      "       [-0.19843329,  0.09049158,  0.1424204 , ...,  0.42741497,\n",
      "        -0.02309322, -0.25303581],\n",
      "       [-0.20481182, -0.39348625, -0.47445171, ...,  0.019211  ,\n",
      "         0.04180672,  0.41829698],\n",
      "       [ 0.07130212,  0.29807033,  0.41087585, ..., -0.10638137,\n",
      "        -0.40970121,  0.06618686]]), 'weights2': array([[-1.34574503,  0.85627803, -0.3151954 , -0.57014087, -2.88091703,\n",
      "         0.58798439,  1.31273907, -1.80210596,  0.1335443 ,  0.23996243,\n",
      "        -0.8541552 , -1.01065679, -1.16527485, -0.1711864 , -0.52841921,\n",
      "        -0.84151654, -0.30851805,  0.70480397,  0.87284375,  0.53457118],\n",
      "       [ 1.11509726, -0.07796002,  0.41503458, -0.88738346, -0.05831157,\n",
      "        -0.02031732, -1.58258052,  0.50003101, -0.77169411, -2.25968602,\n",
      "         1.23795325,  0.78246636, -0.63443103, -0.1641591 , -2.06531168,\n",
      "        -0.59476628,  2.02090238, -0.83436457, -0.53584826, -0.95629038],\n",
      "       [-2.32432082, -1.77996991,  0.62420629, -0.4730769 , -0.82629506,\n",
      "         0.11734709, -1.56743726,  1.19910471, -2.21276614,  0.62474781,\n",
      "        -1.99224297,  0.85913167,  0.73691652, -0.63125419,  0.17786369,\n",
      "        -0.85352438,  0.33211372,  0.61473219,  1.15612178, -0.45515193],\n",
      "       [-0.84207573,  0.57668752, -2.43657992, -0.45148975,  0.39654349,\n",
      "         0.75510343, -0.78694386,  0.6092119 , -1.75286624, -1.21042473,\n",
      "        -0.52316983, -0.48457059, -0.72075013, -0.34090407,  0.37961123,\n",
      "         0.11293197, -1.04533779, -2.02548756, -1.18310651,  1.79988149],\n",
      "       [ 0.35409553, -3.51444184, -0.01318788, -0.98171573, -0.53115146,\n",
      "        -2.23011073,  0.87045007,  0.78672691,  1.39041226, -0.14143029,\n",
      "         1.29037705, -1.37554434,  1.01763874,  0.07875642, -0.27689994,\n",
      "        -0.63916531, -1.0555932 , -0.68084124, -0.10268121,  0.22577712],\n",
      "       [ 1.55864937, -0.11429796,  1.0038384 , -0.45654391,  1.07379643,\n",
      "        -1.05885282, -0.07894682, -2.29551282,  1.09036356, -1.44680011,\n",
      "        -1.58993121, -0.2027915 , -1.0090143 , -0.1254286 , -0.98821815,\n",
      "        -0.48525946, -1.30150721,  0.17271861, -0.85262572,  1.22888379],\n",
      "       [ 0.487378  , -1.79466294, -0.91054383, -1.28861528, -0.1829581 ,\n",
      "         0.98017094, -1.19118571, -1.8888191 ,  1.3405215 ,  0.82615116,\n",
      "        -0.58163709, -0.47035247,  1.09057369,  0.72368993,  0.13053796,\n",
      "        -1.08381016,  1.80440217, -0.42606104, -1.2096096 , -1.23198948],\n",
      "       [-2.20217109,  0.71217346, -0.46488359, -0.65718092,  0.24713123,\n",
      "        -2.3939198 ,  0.87531906, -0.45253724, -0.39427529,  0.10235511,\n",
      "         1.1246364 ,  1.76738948, -1.63253204,  1.34984684, -0.21499364,\n",
      "        -0.36973697, -0.78087403, -0.27434282, -0.34582338, -1.12235362],\n",
      "       [ 1.35982189,  0.45993044,  1.34237329, -1.2550205 , -0.17700674,\n",
      "         0.02358439, -1.58810768,  0.80614692, -0.04493399,  1.19011216,\n",
      "        -1.76288843, -1.62641535, -0.87484066, -0.16871075, -0.56897753,\n",
      "        -0.73106895, -2.1935018 , -1.69101762,  0.74819549, -1.53526942],\n",
      "       [ 1.11827181,  2.33736102, -0.92319251, -0.96254722, -0.42429985,\n",
      "        -1.93487342, -0.29067247,  0.55007116, -0.75631607, -0.40772396,\n",
      "         0.92429455, -1.51361538,  1.03656713, -1.43075874, -0.42238949,\n",
      "        -1.21561658, -1.34591556,  1.01240466, -0.82850536, -1.95577926]])}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model={\n",
    "    'nb_hiddenLayers':1,\n",
    "    'hiddenLayerSize':hls,\n",
    "    'weights1':NN.W1,\n",
    "    'weights2':NN.W2,\n",
    "}\n",
    "arr = np.zeros((1000,2))\n",
    "with open('model.pkl','wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "    \n",
    "with open('model.pkl','rb') as f:\n",
    "   x = pickle.load(f)\n",
    "   print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
